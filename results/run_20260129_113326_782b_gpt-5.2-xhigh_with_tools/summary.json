{
  "run_id": "run_20260129_113326_782b_gpt-5.2-xhigh_after_fix",
  "started_at": "2026-01-29T11:33:26.127520",
  "completed_at": "2026-01-29T11:51:44.217764",
  "status": "completed",
  "total_predictions": 750,
  "parse_success_rate": 1.0,
  "beats_market_rate": 0.4,
  "tie_rate": 0.036,
  "config": {
    "model_ids": [
      "gpt-5.2-xhigh"
    ],
    "strategies": [
      "agentic"
    ],
    "benchmark_dataset": "categorized_data/benchmark_dataset_v2.json",
    "checkpoints": [
      "open_plus_1",
      "pct_25",
      "pct_50",
      "pct_75",
      "close_minus_1"
    ],
    "categories": null,
    "max_iterations": 100,
    "max_search_results": 5,
    "parallelism": 50,
    "tools_enabled": true,
    "n_samples": 750
  },
  "metrics": [
    {
      "model_id": "gpt-5.2-xhigh",
      "strategy": "agentic",
      "checkpoint": null,
      "n_samples": 750,
      "brier_score": 0.19364203333333335,
      "brier_skill_score": -0.25213623078448455,
      "ece": 0.11100666666666667,
      "mce": 0.4050943396226415,
      "accuracy": 0.7093333333333334,
      "precision": 0.4583333333333333,
      "recall": 0.495,
      "f1": 0.47596153846153844,
      "parse_success_rate": 1.0,
      "by_temporal": {}
    },
    {
      "model_id": "gpt-5.2-xhigh",
      "strategy": "agentic",
      "checkpoint": "open_plus_1",
      "n_samples": 150,
      "brier_score": 0.21910883333333336,
      "brier_skill_score": 0.08488838956316413,
      "ece": 0.16196666666666665,
      "mce": 0.40736842105263155,
      "accuracy": 0.6333333333333333,
      "precision": 0.3584905660377358,
      "recall": 0.475,
      "f1": 0.4086021505376344,
      "parse_success_rate": 1.0,
      "by_temporal": {}
    },
    {
      "model_id": "gpt-5.2-xhigh",
      "strategy": "agentic",
      "checkpoint": "pct_25",
      "n_samples": 150,
      "brier_score": 0.20196333333333333,
      "brier_skill_score": -0.09486584554890576,
      "ece": 0.1278,
      "mce": 0.47124999999999995,
      "accuracy": 0.6933333333333334,
      "precision": 0.42105263157894735,
      "recall": 0.4,
      "f1": 0.41025641025641024,
      "parse_success_rate": 1.0,
      "by_temporal": {}
    },
    {
      "model_id": "gpt-5.2-xhigh",
      "strategy": "agentic",
      "checkpoint": "pct_50",
      "n_samples": 150,
      "brier_score": 0.201956,
      "brier_skill_score": -0.34350718467269803,
      "ece": 0.13186666666666666,
      "mce": 0.6971428571428572,
      "accuracy": 0.72,
      "precision": 0.4791666666666667,
      "recall": 0.575,
      "f1": 0.5227272727272727,
      "parse_success_rate": 1.0,
      "by_temporal": {}
    },
    {
      "model_id": "gpt-5.2-xhigh",
      "strategy": "agentic",
      "checkpoint": "pct_75",
      "n_samples": 150,
      "brier_score": 0.196392,
      "brier_skill_score": -0.5951353429464099,
      "ece": 0.1116,
      "mce": 0.595,
      "accuracy": 0.6866666666666666,
      "precision": 0.4146341463414634,
      "recall": 0.425,
      "f1": 0.41975308641975306,
      "parse_success_rate": 1.0,
      "by_temporal": {}
    },
    {
      "model_id": "gpt-5.2-xhigh",
      "strategy": "agentic",
      "checkpoint": "close_minus_1",
      "n_samples": 150,
      "brier_score": 0.14879,
      "brier_skill_score": -0.9601015246258697,
      "ece": 0.09300000000000003,
      "mce": 0.5066666666666666,
      "accuracy": 0.8133333333333334,
      "precision": 0.6666666666666666,
      "recall": 0.6,
      "f1": 0.631578947368421,
      "parse_success_rate": 1.0,
      "by_temporal": {}
    }
  ]
}